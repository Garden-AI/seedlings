{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from garden_ai import GardenClient, Model, step\n",
    "from garden_ai.mlmodel import LocalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the Garden client\n",
    "client = GardenClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert our saved model into a Garden LocalModel\n",
    "with open(\"requirements.txt\", \"r\") as f:\n",
    "    pip_reqs = [line.strip() for line in f.readlines()]\n",
    "\n",
    "local_model = LocalModel(model_name=\"dendrite_segmentation\",\n",
    "                         flavor=\"tensorflow\",\n",
    "                         extra_pip_requirements=pip_reqs,\n",
    "                         local_path=\"model.h5\",\n",
    "                         user_email=client.get_email())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the LocalModel with Garden using the client\n",
    "registered_model = client.register_model(local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Garden's pipelines are composed of steps, so let's make one to run our model\n",
    "@step\n",
    "def run_inference(input_arg: object, model=Model(registered_model.model_name)) -> object:\n",
    "    return model.predict(input_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the step we made and add it to a pipeline\n",
    "pipeline = client.create_pipeline(client.get_email(),  # is this a real name?\n",
    "                                  \"Dendrite Segmentation Test Pipeline\",\n",
    "                                  short_name=registered_model.model_name,\n",
    "                                  steps=(run_inference,),\n",
    "                                  requirements_file=\"requirements.txt\",\n",
    "                                  description=\"Semantic dendrite segmentation via machine learning\",\n",
    "                                  version=\"1.0.0\",\n",
    "                                  tags=[\"materials science\",\n",
    "                                        \"x-ray\",\n",
    "                                        \"segmentation\",\n",
    "                                        \"computer vision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a container designed specially to run our pipeline\n",
    "container_uuid = client.build_container(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register the pipeline and its encompassing container to Garden!\n",
    "func_uuid = client.register_pipeline(pipeline, container_uuid)\n",
    "print(f\"Created function with uuid: {func_uuid}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
