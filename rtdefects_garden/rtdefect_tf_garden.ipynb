{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ee4f4e",
   "metadata": {},
   "source": [
    "# Real Time Defect Analysis: Tensorflow Seedling\n",
    "This notebook will show how to register and run the tenserflow model used in https://github.com/ivem-argonne/real-time-defect-analysis/tree/main with Garden.\n",
    "## Enviorment setup\n",
    "**This notebook is intended to be run from the provided anaconda enviorment.** Run ```conda env create -f ./environment.yml``` to create the enviorment, ```conda activate rtdefects``` to activate it, and then relaunch your Jupyter notebook from inside the enviorment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2e052d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Python version is 3.10.*\n",
    "import sys\n",
    "assert sys.version_info[0] == 3 and sys.version_info[1] == 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b24850e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-11 13:15:06.426295: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import garden_ai\n",
    "from garden_ai import step, GardenClient\n",
    "\n",
    "import json\n",
    "from typing import Optional, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from hashlib import md5\n",
    "from skimage import color, measure, morphology\n",
    "from io import BytesIO\n",
    "from time import perf_counter\n",
    "from hyperspy import io as hsio\n",
    "from scipy.stats import siegelslopes\n",
    "from scipy.interpolate import interp1d\n",
    "import imageio\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b14a3",
   "metadata": {},
   "source": [
    "## Step 1: Register the model\n",
    "The first step is to register the model files with Garden. This model has already been registered with Garden, so you can skip this step.\n",
    "If you did want to re-register the model, run the command ```garden-ai model register short_name path_to_model_file flavor```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcfc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = GardenClient()\n",
    "\n",
    "# Model uri for the pre-registered tensorflow model\n",
    "REGISTERED_MODEL_NAME = \"maxtuecke@gmail.com/rtdefect-tf-model-seedling\"\n",
    "\n",
    "TEST_INPUT_PATH = \"./data/input_image.tiff\"\n",
    "TEST_OUTPUT_PATH = \"./data/tensorflow_output_mask.tiff\"\n",
    "TEST_OUTPUT_DEFECT_PATH = \"./data/tensorflow_output_defect_results.json\"\n",
    "\n",
    "# Pre-made DOI's to register example seedling resources with\n",
    "PIPELINE_DOI = \"10.23677/kd6n-fk59\"\n",
    "GARDEN_DOI = \"10.23677/c66j-tb82\"\n",
    "\n",
    "# Pipeline requirments\n",
    "PIP_REQUIREMENTS = [\"torchvision==0.14.1\", \"torch==1.13.1\", \"segmentation_models.pytorch==0.2.*\", \"pandas==2.0.3\", \"scikit-image==0.21.0\", \"chardet==5.2.0\", \"hyperspy==1.7.5\", \"werkzeug==2.2.3\"]\n",
    "CONDA_REQUIREMENTS = [\"tensorflow>2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98617f37",
   "metadata": {},
   "source": [
    "## Step 2: Create the pipeline\n",
    "Now that we have our model registered with Garden, we can create a pipeline to use it. A pipeline consists of any number of Python functions called steps that will be chained together during execution. Below is an example of three step pipeline, with steps given by the functions ```preprocessing```, ```run_inference``` and ```postprocessing```. Each function must import whatever libraries it requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcacfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorate functions with `@step` so that we can use it to build up a pipeline\n",
    "@step\n",
    "def preprocessing(\n",
    "    input_data: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    import numpy as np\n",
    "    from io import BytesIO\n",
    "    import imageio\n",
    "    from skimage import color, measure, morphology\n",
    "    from typing import Optional, Tuple\n",
    "    \n",
    "    def encode_as_tiff(data: np.ndarray, compress_type: int = 5) -> bytes:\n",
    "        # Convert mask to a uint8-compatible image\n",
    "        data = np.squeeze(data)\n",
    "        assert data.ndim == 2, \"Image must be grayscale\"\n",
    "        assert np.logical_and(data >= 0, data <= 1).all(), \"Image values must be between 0 and 1\"\n",
    "        data = np.array(data * 255, dtype=np.uint8)\n",
    "\n",
    "        # Convert mask to a TIFF-encoded image\n",
    "        output_img = BytesIO()\n",
    "        writer = imageio.get_writer(output_img, format='tiff', mode='i')\n",
    "        writer.append_data(data, meta={'compression': compress_type})\n",
    "        return output_img.getvalue()\n",
    "    \n",
    "    \n",
    "    #Encode image data as tiff\n",
    "    encoded_image_data = encode_as_tiff(input_data, compress_type=5)\n",
    "\n",
    "    # Load the TIFF file into a numpy array\n",
    "    image_gray = imageio.imread(BytesIO(encoded_image_data))\n",
    "\n",
    "    # Preprocess the image data\n",
    "    image = color.gray2rgb(image_gray)  # Convert to RGB\n",
    "    image = np.array(image, dtype=np.float32) / 255  # Convert to float32\n",
    "    image =  np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Check the shape\n",
    "    assert image.ndim == 4, \"Expects a stack of images\"\n",
    "    assert image.shape[-1] == 3, \"Expects 3 output channels\"\n",
    "    assert image.dtype == np.float32, \"Expects np.float32\"\n",
    "    assert 0 <= np.min(image) and np.max(image) <= 1, \"Image values should be in [0, 1]\"\n",
    "    \n",
    "    return image\n",
    "\n",
    "@step\n",
    "def run_inference(\n",
    "    input_data: np.ndarray,\n",
    "    model=garden_ai.Model(REGISTERED_MODEL_NAME),  # loads the registered model by name, with a `.predict()` method\n",
    ") -> np.ndarray:\n",
    "    return model.predict(input_data)\n",
    "    \n",
    "@step\n",
    "def postprocessing(input_data: np.ndarray) -> np.ndarray:\n",
    "    import numpy as np\n",
    "    from io import BytesIO\n",
    "    import imageio\n",
    "    from skimage import color, measure, morphology\n",
    "    from typing import Optional, Tuple\n",
    "    \n",
    "    def encode_as_tiff(data: np.ndarray, compress_type: int = 5) -> bytes:\n",
    "        # Convert mask to a uint8-compatible image\n",
    "        data = np.squeeze(data)\n",
    "        assert data.ndim == 2, \"Image must be grayscale\"\n",
    "        assert np.logical_and(data >= 0, data <= 1).all(), \"Image values must be between 0 and 1\"\n",
    "        data = np.array(data * 255, dtype=np.uint8)\n",
    "\n",
    "        # Convert mask to a TIFF-encoded image\n",
    "        output_img = BytesIO()\n",
    "        writer = imageio.get_writer(output_img, format='tiff', mode='i')\n",
    "        writer.append_data(data, meta={'compression': compress_type})\n",
    "        return output_img.getvalue()\n",
    "\n",
    "    def analyze_defects(mask: np.ndarray, min_size: int = 50) -> Tuple[dict, np.ndarray]:\n",
    "        mask = morphology.remove_small_objects(mask, min_size=min_size)\n",
    "        mask = morphology.remove_small_holes(mask, min_size)\n",
    "        mask = morphology.binary_erosion(mask, morphology.square(1))\n",
    "        output = {'void_frac': mask.sum() / (mask.shape[0] * mask.shape[1])}\n",
    "\n",
    "        # Assign labels to the labeled regions\n",
    "        labels = measure.label(mask)\n",
    "        output['void_count'] = int(labels.max())\n",
    "\n",
    "        # Compute region properties\n",
    "        props = measure.regionprops(labels, mask)\n",
    "        radii = [p['equivalent_diameter'] / 2 for p in props]\n",
    "        output['radii'] = radii\n",
    "        output['radii_average'] = np.average(radii)\n",
    "        output['positions'] = [p['centroid'] for p in props]\n",
    "        return output, labels\n",
    "    \n",
    "    \n",
    "    # Make it into a bool array\n",
    "    segment = np.squeeze(input_data)\n",
    "    mask = segment > 0.9\n",
    "\n",
    "    # Generate the analysis results\n",
    "    defect_results, _ = analyze_defects(mask)  # Discard the labeled output\n",
    "\n",
    "    # Convert mask to a TIFF-encoded image\n",
    "    mask_data = encode_as_tiff(mask)\n",
    "    \n",
    "    output = {\"mask\" : mask_data, \"defect_results\" : defect_results}\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1288b14",
   "metadata": {},
   "source": [
    "With our steps defined, we can now make the pipeline object. The parameter ```steps``` is a tuple giving the step functions in the desired order of execution, from left to right.  The output of the previous step will be send to the next. Note that at this point the pipeline is still a local object and has not been registered with Garden.\n",
    "\n",
    "**NOTE:** We are manually setting doi to PIPELINE_DOI which is pre-generated so the pipeline will always be registered to the same place. If you want to register a new pipeline with a new doi, just remove the argument and a new one will be generated. We will also do this when creating a new Garden later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889e304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdefect_pipeline = client.create_pipeline(\n",
    "    title=\"RT Defect Analysis TF Demo Pipeline\",\n",
    "    python_version=f\"{sys.version_info[0]}.{sys.version_info[1]}.{sys.version_info[2]}\",\n",
    "    pip_dependencies=PIP_REQUIREMENTS,\n",
    "    conda_dependencies=CONDA_REQUIREMENTS,\n",
    "    steps=(preprocessing, run_inference, postprocessing),  # steps run in order left to right, passing output to subsequent steps\n",
    "    authors=[\n",
    "        \"Ward, Logan\",\n",
    "    ],\n",
    "    contributors=[\"Tuecke, Max\"],\n",
    "    version=\"0.0.1\",\n",
    "    year=2023,\n",
    "    tags=[],\n",
    "    short_name=\"rtdefect_tf\", # will use this name to execute the pipeline later\n",
    "    doi=PIPELINE_DOI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d39a3",
   "metadata": {},
   "source": [
    "## Step 3: Register the pipeline\n",
    "Now that we have our pipeline defined, it is time to register it with Garden. Normally, registering a new pipeline creates a new container using the pipeline dependencies and then uploads the pipeline to Garden. However, a container for this pipeline already exists, so we will just manually set the container_id and skip the time-consuming process of building a new container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4925c178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered pipeline '10.23677/kd6n-fk59'!\n"
     ]
    }
   ],
   "source": [
    "#container_id = client.build_container(rtdefect_pipeline) # if you want to build a fresh container instead\n",
    "\n",
    "container_id = \"cb99321a-7e27-4d13-b2ac-1855ce28e90d\"\n",
    "rtdefect_pipeline.container_uuid = container_id\n",
    "\n",
    "client.register_pipeline(rtdefect_pipeline, container_id)\n",
    "print(f\"Registered pipeline '{rtdefect_pipeline.doi}'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d5a4d",
   "metadata": {},
   "source": [
    "## Sanity check: Pipeline execution\n",
    "At this point, you should now have a new registered pipline with Garden. To confirm that the pipeline exists and is working, let's quickly fetch it from Garden using the new DOI and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "717bc553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8m/72xk7hd500d_21k738y76v7c0000gn/T/ipykernel_39786/253591368.py:11: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  data: np.ndarray = function(path)\n",
      "ERROR:hyperspy.io:If this file format is supported, please report this error to the HyperSpy developers.\n"
     ]
    }
   ],
   "source": [
    "# rtdefects input image loader - takes a path to an input image and loads it into np.ndarray for the pipeline.\n",
    "def load_rtdefects_input(path: Path) -> np.ndarray:\n",
    "    # Step 1: attempt to read it with imageio\n",
    "    load_functions = [\n",
    "        imageio.imread,\n",
    "        lambda x: hsio.load(x).data\n",
    "    ]\n",
    "    data = None\n",
    "    for function in load_functions:\n",
    "        try:\n",
    "            data: np.ndarray = function(path)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    if data is None:\n",
    "        raise ValueError(f'Failed to load image from {path}')\n",
    "\n",
    "    # Standardize the format\n",
    "    data = np.array(data, dtype=np.float32)\n",
    "    data = np.squeeze(data)\n",
    "    if data.ndim == 3:\n",
    "        data = color.rgb2gray(data)\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    return data\n",
    "\n",
    "demo_input = load_rtdefects_input(TEST_INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4760e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/maxtuecke/anaconda3/envs/rtdefects_test/lib/python3.10/site-packages/rich/live.py:229: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">⠋</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> executing remotely on endpoint 6d39d01e-2955-47b9-a1f6-50f147e650d6</span></pre>\n"
      ],
      "text/plain": [
       "/Users/maxtuecke/anaconda3/envs/rtdefects_test/lib/python3.10/site-packages/rich/live.py:229: UserWarning: install \n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "\u001b[32m⠋\u001b[0m \u001b[1;32m executing remotely on endpoint 6d39d01e-2955-47b9-a1f6-50f147e650d6\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h\r",
       "\u001b[1A\u001b[2K"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Pipeline executed with correct results.\n"
     ]
    }
   ],
   "source": [
    "# results we want to reproduce with our pipeline\n",
    "with open(TEST_OUTPUT_PATH, \"rb\") as img:\n",
    "\texpected_mask = img.read()\n",
    "expected_defects = json.load(open(TEST_OUTPUT_DEFECT_PATH))\n",
    "\n",
    "# fetch the new pipeline from Garden with the DOI\n",
    "# Note: this pipeline is not discoverable yet as it has not been added to a Garden\n",
    "rtdefect_remote = client.get_registered_pipeline(PIPELINE_DOI)\n",
    "\n",
    "results = rtdefect_remote(\n",
    "    demo_input,\n",
    "    endpoint=\"86a47061-f3d9-44f0-90dc-56ddc642c000\",  # execute on Globus Compute endpoint of choice\n",
    ")\n",
    "\n",
    "assert results[\"mask\"] == expected_mask\n",
    "assert json.loads(json.dumps(results[\"defect_results\"])) == expected_defects #use json here to change tuples to lists, makes result same format as expected\n",
    "\n",
    "print(\"Done! Pipeline executed with correct results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f458ed",
   "metadata": {},
   "source": [
    "## Step 4: Create and publish a new Garden\n",
    "The final step is to add the newly registered pipeline to a Garden and publish it. First, create a new Garden and add the pipline's DOI to its pipeline_ids list.\n",
    "**Note:** A Garden can have multiple pipelines and models associated with it. See the ```rtdefect_torch_garden``` notebook for an example of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a0b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "rtdefect_garden_tf = client.create_garden(\n",
    "    title=\"RT Defect Analysis TF Demo Garden\",\n",
    "    authors=[\"Max Tuecke\"],\n",
    "    description=\"Recreates the RT Defect Analysis tensorflow model from https://github.com/ivem-argonne/real-time-defect-analysis/tree/main\",\n",
    "    doi=GARDEN_DOI,\n",
    ")\n",
    "# include the pipeline by just its DOI:\n",
    "rtdefect_garden_tf.pipeline_ids += [PIPELINE_DOI]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f696a",
   "metadata": {},
   "source": [
    "Now all thats left is to publish the new Garden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d42085de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish our new garden, making it (and its pipeline) discoverable by other garden users\n",
    "client.publish_garden_metadata(rtdefect_garden_tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1aab00",
   "metadata": {},
   "source": [
    "## Sanity check: Garden search and execution\n",
    "Let's make sure that our new Garden is now published by searching for it with the CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c106904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m{\u001b[0m\r\n",
      "  \u001b[1;34m\"gmeta\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "    \u001b[1m{\u001b[0m\r\n",
      "      \u001b[1;34m\"@datatype\"\u001b[0m: \u001b[32m\"GMetaResult\"\u001b[0m,\r\n",
      "      \u001b[1;34m\"entries\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "        \u001b[1m{\u001b[0m\r\n",
      "          \u001b[1;34m\"content\"\u001b[0m: \u001b[1m{\u001b[0m\r\n",
      "            \u001b[1;34m\"pipeline_aliases\"\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\r\n",
      "            \u001b[1;34m\"year\"\u001b[0m: \u001b[32m\"2023\"\u001b[0m,\r\n",
      "            \u001b[1;34m\"description\"\u001b[0m: \u001b[32m\"Recreates the RT Defect Analysis tensorflow model from https://github.com/ivem-argonne/real-time-defect-analysis/tree/main\"\u001b[0m,\r\n",
      "            \u001b[1;34m\"language\"\u001b[0m: \u001b[32m\"en\"\u001b[0m,\r\n",
      "            \u001b[1;34m\"title\"\u001b[0m: \u001b[32m\"RT Defect Analysis TF Demo Garden\"\u001b[0m,\r\n",
      "            \u001b[1;34m\"version\"\u001b[0m: \u001b[32m\"0.0.1\"\u001b[0m,\r\n",
      "            \u001b[1;34m\"tags\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "            \u001b[1;34m\"pipelines\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "              \u001b[1m{\u001b[0m\r\n",
      "                \u001b[1;34m\"models\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[1m{\u001b[0m\r\n",
      "                    \u001b[1;34m\"flavor\"\u001b[0m: \u001b[32m\"tensorflow\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"user_email\"\u001b[0m: \u001b[32m\"maxtuecke@gmail.com\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"full_name\"\u001b[0m: \u001b[32m\"maxtuecke@gmail.com/rtdefect-tf-model-seedling\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"model_name\"\u001b[0m: \u001b[32m\"rtdefect-tf-model-seedling\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"serialize_type\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\r\n",
      "                    \u001b[1;34m\"mlflow_name\"\u001b[0m: \u001b[32m\"maxtuecke@gmail.com-rtdefect-tf-model-seedling\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"dataset\"\u001b[0m: \u001b[3;35mnull\u001b[0m\r\n",
      "                  \u001b[1m}\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"year\"\u001b[0m: \u001b[32m\"2023\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"description\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\r\n",
      "                \u001b[1;34m\"func_uuid\"\u001b[0m: \u001b[32m\"cb7c1b33-4e69-4e63-8d65-a82602488270\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"model_full_names\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[32m\"maxtuecke@gmail.com/rtdefect-tf-model-seedling\"\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"title\"\u001b[0m: \u001b[32m\"RT Defect Analysis TF Demo Pipeline\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"steps\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[1m{\u001b[0m\r\n",
      "                    \u001b[1;34m\"input_info\"\u001b[0m: \u001b[32m\"{'input_data': <class 'numpy.ndarray'>}\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"func\"\u001b[0m: \u001b[32m\"preprocessing: (input_data: numpy.ndarray) -> numpy.ndarray\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"description\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\r\n",
      "                    \u001b[1;34m\"model_full_names\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                    \u001b[1;34m\"contributors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                    \u001b[1;34m\"output_info\"\u001b[0m: \u001b[32m\"return: <class 'numpy.ndarray'>\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"source\"\u001b[0m: \u001b[32m\"@step\\ndef preprocessing(\\n    input_data: np.ndarray,\\n) -> np.ndarray:\\n    import numpy as np\\n    from io import BytesIO\\n    import imageio\\n    from skimage import color, measure, morphology\\n    from typing import Optional, Tuple\\n    \\n    def encode_as_tiff(data: np.ndarray, compress_type: int = 5) -> bytes:\\n        # Convert mask to a uint8-compatible image\\n        data = np.squeeze(data)\\n        assert data.ndim == 2, \\\"Image must be grayscale\\\"\\n        assert np.logical_and(data >= 0, data <= 1).all(), \\\"Image values must be between 0 and 1\\\"\\n        data = np.array(data * 255, dtype=np.uint8)\\n\\n        # Convert mask to a TIFF-encoded image\\n        output_img = BytesIO()\\n        writer = imageio.get_writer(output_img, format='tiff', mode='i')\\n        writer.append_data(data, meta={'compression': compress_type})\\n        return output_img.getvalue()\\n    \\n    \\n    #Encode image data as tiff\\n    encoded_image_data = encode_as_tiff(input_data, compress_type=5)\\n\\n    # Load the TIFF file into a numpy array\\n    image_gray = imageio.imread(BytesIO(encoded_image_data))\\n\\n    # Preprocess the image data\\n    image = color.gray2rgb(image_gray)  # Convert to RGB\\n    image = np.array(image, dtype=np.float32) / 255  # Convert to float32\\n    image =  np.expand_dims(image, axis=0)\\n\\n    # Check the shape\\n    assert image.ndim == 4, \\\"Expects a stack of images\\\"\\n    assert image.shape[-1] == 3, \\\"Expects 3 output channels\\\"\\n    assert image.dtype == np.float32, \\\"Expects np.float32\\\"\\n    assert 0 <= np.min(image) and np.max(image) <= 1, \\\"Image values should be in [0, 1]\\\"\\n    \\n    return image\\n\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"title\"\u001b[0m: \u001b[32m\"preprocessing\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"authors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\r\n",
      "                  \u001b[1m}\u001b[0m,\r\n",
      "                  \u001b[1m{\u001b[0m\r\n",
      "                    \u001b[1;34m\"input_info\"\u001b[0m: \u001b[32m\"{'input_data': <class 'numpy.ndarray'>}\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"func\"\u001b[0m: \u001b[32m\"run_inference: (input_data: numpy.ndarray, model=<__main__._Model object at 0x7f9e80681b40>) -> numpy.ndarray\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"description\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\r\n",
      "                    \u001b[1;34m\"model_full_names\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                      \u001b[32m\"maxtuecke@gmail.com/rtdefect-tf-model-seedling\"\u001b[0m\r\n",
      "                    \u001b[1m]\u001b[0m,\r\n",
      "                    \u001b[1;34m\"contributors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                    \u001b[1;34m\"output_info\"\u001b[0m: \u001b[32m\"return: <class 'numpy.ndarray'>\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"source\"\u001b[0m: \u001b[32m\"@step\\ndef run_inference(\\n    input_data: np.ndarray,\\n    model=garden_ai.Model(REGISTERED_MODEL_NAME),  # loads the registered model by name, with a `.predict()` method\\n) -> np.ndarray:\\n    return model.predict(input_data)\\n\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"title\"\u001b[0m: \u001b[32m\"run_inference\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"authors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\r\n",
      "                  \u001b[1m}\u001b[0m,\r\n",
      "                  \u001b[1m{\u001b[0m\r\n",
      "                    \u001b[1;34m\"input_info\"\u001b[0m: \u001b[32m\"{'input_data': <class 'numpy.ndarray'>}\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"func\"\u001b[0m: \u001b[32m\"postprocessing: (input_data: numpy.ndarray) -> numpy.ndarray\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"description\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\r\n",
      "                    \u001b[1;34m\"model_full_names\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                    \u001b[1;34m\"contributors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                    \u001b[1;34m\"output_info\"\u001b[0m: \u001b[32m\"return: <class 'numpy.ndarray'>\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"source\"\u001b[0m: \u001b[32m\"@step\\ndef postprocessing(input_data: np.ndarray) -> np.ndarray:\\n    import numpy as np\\n    from io import BytesIO\\n    import imageio\\n    from skimage import color, measure, morphology\\n    from typing import Optional, Tuple\\n    \\n    def encode_as_tiff(data: np.ndarray, compress_type: int = 5) -> bytes:\\n        # Convert mask to a uint8-compatible image\\n        data = np.squeeze(data)\\n        assert data.ndim == 2, \\\"Image must be grayscale\\\"\\n        assert np.logical_and(data >= 0, data <= 1).all(), \\\"Image values must be between 0 and 1\\\"\\n        data = np.array(data * 255, dtype=np.uint8)\\n\\n        # Convert mask to a TIFF-encoded image\\n        output_img = BytesIO()\\n        writer = imageio.get_writer(output_img, format='tiff', mode='i')\\n        writer.append_data(data, meta={'compression': compress_type})\\n        return output_img.getvalue()\\n\\n    def analyze_defects(mask: np.ndarray, min_size: int = 50) -> Tuple[dict, np.ndarray]:\\n        mask = morphology.remove_small_objects(mask, min_size=min_size)\\n        mask = morphology.remove_small_holes(mask, min_size)\\n        mask = morphology.binary_erosion(mask, morphology.square(1))\\n        output = {'void_frac': mask.sum() / (mask.shape[0] * mask.shape[1])}\\n\\n        # Assign labels to the labeled regions\\n        labels = measure.label(mask)\\n        output['void_count'] = int(labels.max())\\n\\n        # Compute region properties\\n        props = measure.regionprops(labels, mask)\\n        radii = [p['equivalent_diameter'] / 2 for p in props]\\n        output['radii'] = radii\\n        output['radii_average'] = np.average(radii)\\n        output['positions'] = [p['centroid'] for p in props]\\n        return output, labels\\n    \\n    \\n    # Make it into a bool array\\n    segment = np.squeeze(input_data)\\n    mask = segment > 0.9\\n\\n    # Generate the analysis results\\n    defect_results, _ = analyze_defects(mask)  # Discard the labeled output\\n\\n    # Convert mask to a TIFF-encoded image\\n    mask_data = encode_as_tiff(mask)\\n    \\n    output = {\\\"mask\\\" : mask_data, \\\"defect_results\\\" : defect_results}\\n    \\n    return output\\n\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"title\"\u001b[0m: \u001b[32m\"postprocessing\"\u001b[0m,\r\n",
      "                    \u001b[1;34m\"authors\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\r\n",
      "                  \u001b[1m}\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"version\"\u001b[0m: \u001b[32m\"0.0.1\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"conda_dependencies\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[32m\"tensorflow>2\"\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"papers\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"tags\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"pip_dependencies\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[32m\"chardet==5.2.0\"\u001b[0m,\r\n",
      "                  \u001b[32m\"werkzeug==2.2.3\"\u001b[0m,\r\n",
      "                  \u001b[32m\"torchvision==0.14.1\"\u001b[0m,\r\n",
      "                  \u001b[32m\"segmentation_models.pytorch==0.2.*\"\u001b[0m,\r\n",
      "                  \u001b[32m\"mlflow-skinny==2.5.0\"\u001b[0m,\r\n",
      "                  \u001b[32m\"pandas==2.0.3\"\u001b[0m,\r\n",
      "                  \u001b[32m\"torch==1.13.1\"\u001b[0m,\r\n",
      "                  \u001b[32m\"scikit-image==0.21.0\"\u001b[0m,\r\n",
      "                  \u001b[32m\"hyperspy==1.7.5\"\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"repositories\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"python_version\"\u001b[0m: \u001b[32m\"3.10.12\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"short_name\"\u001b[0m: \u001b[32m\"rtdefect_tf\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"contributors\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[32m\"Tuecke, Max\"\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m,\r\n",
      "                \u001b[1;34m\"doi\"\u001b[0m: \u001b[32m\"10.23677/kd6n-fk59\"\u001b[0m,\r\n",
      "                \u001b[1;34m\"authors\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "                  \u001b[32m\"Ward, Logan\"\u001b[0m\r\n",
      "                \u001b[1m]\u001b[0m\r\n",
      "              \u001b[1m}\u001b[0m\r\n",
      "            \u001b[1m]\u001b[0m,\r\n",
      "            \u001b[1;34m\"publisher\"\u001b[0m: \u001b[32m\"Garden-AI\"\u001b[0m,\r\n",
      "            \u001b[1;34m\"contributors\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "              \u001b[32m\"Tuecke, Max\"\u001b[0m,\r\n",
      "              \u001b[32m\"Ward, Logan\"\u001b[0m\r\n",
      "            \u001b[1m]\u001b[0m,\r\n",
      "            \u001b[1;34m\"pipeline_ids\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "              \u001b[32m\"10.23677/kd6n-fk59\"\u001b[0m\r\n",
      "            \u001b[1m]\u001b[0m,\r\n",
      "            \u001b[1;34m\"authors\"\u001b[0m: \u001b[1m[\u001b[0m\r\n",
      "              \u001b[32m\"Max Tuecke\"\u001b[0m\r\n",
      "            \u001b[1m]\u001b[0m,\r\n",
      "            \u001b[1;34m\"doi\"\u001b[0m: \u001b[32m\"10.23677/c66j-tb82\"\u001b[0m\r\n",
      "          \u001b[1m}\u001b[0m,\r\n",
      "          \u001b[1;34m\"entry_id\"\u001b[0m: \u001b[3;35mnull\u001b[0m,\r\n",
      "          \u001b[1;34m\"matched_principal_sets\"\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m]\u001b[0m\r\n",
      "        \u001b[1m}\u001b[0m\r\n",
      "      \u001b[1m]\u001b[0m,\r\n",
      "      \u001b[1;34m\"subject\"\u001b[0m: \u001b[32m\"10.23677/c66j-tb82\"\u001b[0m,\r\n",
      "      \u001b[1;34m\"@version\"\u001b[0m: \u001b[32m\"2019-08-27\"\u001b[0m\r\n",
      "    \u001b[1m}\u001b[0m\r\n",
      "  \u001b[1m]\u001b[0m,\r\n",
      "  \u001b[1;34m\"offset\"\u001b[0m: \u001b[1;36m0\u001b[0m,\r\n",
      "  \u001b[1;34m\"@datatype\"\u001b[0m: \u001b[32m\"GSearchResult\"\u001b[0m,\r\n",
      "  \u001b[1;34m\"total\"\u001b[0m: \u001b[1;36m1\u001b[0m,\r\n",
      "  \u001b[1;34m\"@version\"\u001b[0m: \u001b[32m\"2017-09-01\"\u001b[0m,\r\n",
      "  \u001b[1;34m\"count\"\u001b[0m: \u001b[1;36m1\u001b[0m,\r\n",
      "  \u001b[1;34m\"has_next_page\"\u001b[0m: \u001b[3;91mfalse\u001b[0m\r\n",
      "\u001b[1m}\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!garden-ai garden search --title=\"RT Defect Analysis TF Demo Garden\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d388c",
   "metadata": {},
   "source": [
    "Finally, let's make sure we can run the pipline in the new Garden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ac3512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": [
       "\u001b[?25l"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\u001b[?25h</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[?25h"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'void_frac': 0.0023212432861328125, 'void_count': 7, 'radii': [10.940041919714261, 4.442433223290478, 10.704744696916627, 7.998767850296815, 5.352372348458314, 14.439285835884782, 14.820047957642227], 'radii_average': 9.813956261743357, 'positions': [(120.55319148936171, 259.25531914893617), (312.98387096774195, 259.11290322580646), (589.8416666666667, 932.0722222222222), (661.0995024875622, 1017.3781094527363), (856.2444444444444, 865.1), (953.7862595419847, 682.2290076335878), (1002.4869565217391, 555.6579710144928)]}\n"
     ]
    }
   ],
   "source": [
    "# Get the newly published Garden with its DOI\n",
    "rtdefects_garden_published = client.get_published_garden(GARDEN_DOI)\n",
    "\n",
    "# Run its pipeline by calling the pipelines' short_name\n",
    "results = rtdefects_garden_published.rtdefect_tf(demo_input, endpoint=\"86a47061-f3d9-44f0-90dc-56ddc642c000\")\n",
    "print(results[\"defect_results\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604400ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
